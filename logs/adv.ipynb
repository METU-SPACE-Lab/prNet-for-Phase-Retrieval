{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from dataloaders.dataloader_v1 import get_loader\n",
    "import torch\n",
    "from wcmatch.pathlib import Path\n",
    "from utils.utils import crop_center_half, ifft2d, normalize, flip_to_minimize_loss\n",
    "from utils.algorithms import get_algorithm\n",
    "from matplotlib import pyplot as plt\n",
    "from einops import rearrange, repeat\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from models.denoisers import get_denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/hdd_mnt/onurcan/onurk/datasets/adversarial_alpha_3\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "batch_size = 22\n",
    "stage = \"train\"\n",
    "dataloader = get_loader(\"adversarial_dataset\", stage, root, batch_size)\n",
    "stage = \"val\"\n",
    "val_dataloader = get_loader(\"adversarial_dataset\", stage, root, batch_size)\n",
    "stage = \"test\"\n",
    "test_dataloader = get_loader(\"adversarial_dataset\", stage, root, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.resnet = torchvision.models.resnet50(pretrained=True)\n",
    "        self.resnet.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # no torch.nn.functional.sigmoid(\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuartis/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/kuartis/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "adversarial_denoiser = get_denoiser(\"UNet2D\")().to(device)\n",
    "critic = Critic().to(device)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(adversarial_denoiser.parameters(), lr=3e-5, betas=(0.95, 0.999), weight_decay=1e-5)\n",
    "critic_optimizer = torch.optim.AdamW(critic.parameters(), lr=3e-5, betas=(0.95, 0.999), weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, filename=\"notebooks/py_log_adversarial_alpha_3__.log\", filemode=\"w\", format='%(asctime)s %(levelname)-8s %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "continue_from_epoch = 0\n",
    "N_epochs = 20\n",
    "dataloader_len = len(dataloader)\n",
    "\n",
    "from diffusers.optimization import get_scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=300,\n",
    "    num_training_steps=(dataloader_len * N_epochs) //\n",
    "    1,\n",
    ")\n",
    "\n",
    "min_test_loss = float(\"inf\")\n",
    "\n",
    "logging.info(\"epoch (index_dataloader/dataloader_len), loss_value.item(), epoch_losses.mean()\")\n",
    "for epoch in range(continue_from_epoch, N_epochs):\n",
    "    adversarial_denoiser.train()\n",
    "    critic.train()\n",
    "    \n",
    "    epoch_losses = np.array([])\n",
    "    epoch_losses_critic = np.array([])\n",
    "    \n",
    "    for index_dataloader, (target_im, robust_output, output) in enumerate(dataloader):\n",
    "        target_im = target_im.to(device).float()\n",
    "        robust_output = robust_output.to(device).float()\n",
    "        output = output.to(device).float()\n",
    "        \n",
    "        # Train critic\n",
    "        denoised_output = adversarial_denoiser(output / 255.0, 0) * 255.0 + output\n",
    "        \n",
    "        real_output = critic(target_im)\n",
    "        fake_output = critic(denoised_output)\n",
    "                    \n",
    "        critic_loss = -torch.mean(real_output) + torch.mean(fake_output)\n",
    "        \n",
    "        # Gradient penalty\n",
    "        lambda_gp = 10.0\n",
    "        alpha = torch.rand(target_im.size(0), 1, 1, 1).to(device)\n",
    "        interpolates = (alpha * target_im + (1 - alpha) * denoised_output).requires_grad_(True)\n",
    "        d_interpolates = critic(interpolates)\n",
    "        gradients = autograd.grad(outputs=d_interpolates, inputs=interpolates,\n",
    "                                  grad_outputs=torch.ones(d_interpolates.size()).to(device),\n",
    "                                  create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()        \n",
    "        critic_loss += lambda_gp * gradient_penalty\n",
    "        \n",
    "        critic_loss.backward()\n",
    "        critic_optimizer.step()\n",
    "        critic_optimizer.zero_grad()\n",
    "        \n",
    "        epoch_losses_critic = np.append(epoch_losses_critic, critic_loss.item())\n",
    "        \n",
    "        # Train denoiser\n",
    "        denoised_output = adversarial_denoiser(output / 255.0, 0) * 255.0 + output\n",
    "        \n",
    "        fake_output = critic(denoised_output)\n",
    "        \n",
    "        reconstruction_loss = loss(denoised_output, target_im)\n",
    "        adversarial_loss = -torch.mean(fake_output)\n",
    "        \n",
    "        lambda_ = 0.7\n",
    "        total_loss = reconstruction_loss\n",
    "        if epoch / N_epochs >= 0.2:\n",
    "            total_loss += lambda_ * adversarial_loss\n",
    "                \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        epoch_losses = np.append(epoch_losses, total_loss.item())\n",
    "        \n",
    "        if (index_dataloader+1) % (dataloader_len // 200) == 0:\n",
    "            logging.info(f\"train: {epoch} ({index_dataloader}/{dataloader_len}), {total_loss.item()}, {epoch_losses.mean()} | {critic_loss.item()}, {epoch_losses_critic.mean()}\")\n",
    "    \n",
    "    adversarial_denoiser.eval()\n",
    "    critic.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_losses_val = np.array([])\n",
    "        epoch_losses_old_val = np.array([])\n",
    "        for target_im, robust_output, output in val_dataloader:\n",
    "            target_im = target_im.to(device).float()\n",
    "            robust_output = robust_output.to(device).float()\n",
    "            output = output.to(device).float()\n",
    "\n",
    "            denoised_output = adversarial_denoiser(output / 255.0, 0) * 255.0 + output\n",
    "\n",
    "            # loss calculation\n",
    "            loss_value = loss(denoised_output, target_im)\n",
    "            epoch_losses_val = np.append(epoch_losses_val, loss_value.item())\n",
    "            loss_value_old = loss(output, target_im)\n",
    "            epoch_losses_old_val = np.append(epoch_losses_old_val, loss_value_old.item())\n",
    "\n",
    "        logging.info(f\"val: {epoch}, {epoch_losses_val.mean()}, {epoch_losses_old_val.mean()}\")\n",
    "        \n",
    "        epoch_losses_val = np.array([])\n",
    "        epoch_losses_old_val = np.array([])\n",
    "        for target_im, robust_output, output in test_dataloader:\n",
    "            target_im = target_im.to(device).float()\n",
    "            robust_output = robust_output.to(device).float()\n",
    "            output = output.to(device).float()\n",
    "\n",
    "            denoised_output = adversarial_denoiser(output / 255.0, 0) * 255.0 + output\n",
    "\n",
    "            # loss calculation\n",
    "            loss_value = loss(denoised_output, target_im)\n",
    "            epoch_losses_val = np.append(epoch_losses_val, loss_value.item())\n",
    "            loss_value_old = loss(output, target_im)\n",
    "            epoch_losses_old_val = np.append(epoch_losses_old_val, loss_value_old.item())\n",
    "        \n",
    "        logging.info(f\"test: {epoch}, {epoch_losses_val.mean()}, {epoch_losses_old_val.mean()}\")\n",
    "        \n",
    "        if(epoch % 14 == 7):\n",
    "            torch.save(adversarial_denoiser.state_dict(), f\"save_adversarial_alpha_3_{epoch}_.pth\")\n",
    "        \n",
    "        # save the best model\n",
    "        if(min_test_loss > epoch_losses_val.mean()):\n",
    "            min_test_loss = epoch_losses_val.mean()\n",
    "            torch.save(adversarial_denoiser.state_dict(), \"save_adversarial_alpha_3_best_.pth\")\n",
    "            \n",
    "torch.save(adversarial_denoiser.state_dict(), \"save_adversarial_alpha_3_last_.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
